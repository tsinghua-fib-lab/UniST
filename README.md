# UniST

A pytorch implementation for the paper: [**UniST: A Prompt-Empowered Universal Model for Urban Spatio-Temporal Prediction**](https://arxiv.org/abs/2402.11838).

[Yuan Yuan](https://scholar.google.com/citations?user=1AaWLJ8AAAAJ), [Jingtao Ding](https://scholar.google.com/citations?user=_TAJECAAAAAJ), [Jie Feng](https://scholar.google.com/citations?user=uvLx-GAAAAAJ), [Depeng Jin](), [Yong Li](https://scholar.google.com/citations?user=kmgzPeQAAAAJ)

**[FIBLAB](https://fi.ee.tsinghua.edu.cn/)@[Tsinghua University](https://www.tsinghua.edu.cn/)**

-----

The repo currently includes code implementations for the following tasks:

> **Short-term Prediction**: We provide all scripts  for the reproduction of short-term prediction results in this repo.

> **Long-term Prediction**: We provide all scripts  for the reproduction of long-term prediction results in this repo.

> **Few-shot Prediction**: UniST can generalize well to scenarios with limited training data, making it to be data-efficient.

> **Zero-shot Prediction**: UniST is demonstrated to generalize well on unseen spatio-temporal scenarios, making it a nice alternative as the fundamental backbone of the foundation spatio-temporal model.


## ğŸ‰ Updates

ğŸ“¢: **News** (2024.06) Introduction of our work in [é‡å­ä½](https://mp.weixin.qq.com/s/4rxmEx-8cYfgWHX6ct9gag), [æ—¶ç©ºæ¢ç´¢ä¹‹æ—…](https://mp.weixin.qq.com/s/KoARxX0ko1nPHJbsAh5HQw), [æ—¶åºäºº](https://mp.weixin.qq.com/s/SxoYTCFa5JIuiBaBDVDecA) are available.

ğŸ“¢: **News** (2024.05) UniST has been accepted to **KDD 2024**.



## Introduction
ğŸ† By capturing the  underlying commonalities across multiple spatio-temporal scenarios, UniST breaks the  conventional practice that train separate models for different datasets, and has demonstrated superior performance and powerful generalization capability across diverse urban scenarios.
![UniST](./assets/figure1.jpg "")

## Overall Architecture
ğŸŒŸ The training of UniST consists of two stages: (i) large-scale spatio-temporal pre-training, and (ii) spatio-temporal knowledge-guided prompt tuning. 
![OverallArchi](./assets/model_all.jpg "")

The pseudo-code of UniST is as simple as the following:
![Alg](./assets/alg.jpg "")

## âš– Foundation models for spatio-temporal prediction

| Model  | Data Format | Data Scalability | Few-shot | Zero-shot | Computation Cost | Memory Cost |
|--------|-------------|------------------|----------|-----------|------------------|-------------|
| PromptST [1] | Grid | **âœ—** | **âœ—** | **âœ—** | Low | Low |
| GPT-ST [2]   | Graph | **âœ—** | **âœ—** | **âœ—** | Low | Low |
| STEP [3]    | Graph |  **âœ—** | **âœ—** | **âœ—** | Low | Low |
| ST-SSL [4]   | Graph |  **âœ—** | **âœ—** | **âœ—** | Low | Low |
| TrafficBERT [5] | Grid/Graph  |  **âœ“** | **âœ—** | **âœ—** | Low | Low |
| TFM [6]    | Graph | **âœ—** | **âœ—** | **âœ—** | Low | Low |
| UrbanGPT [7]     | Grid | **âœ“**<sup>(a)</sup>  | **âœ“**<sup>(a)</sup> | **âœ“**<sup>(a)</sup> | High | High |
| STG-LLM [8]    | Graph | **âœ—**  | **âœ—** | **âœ—** | High | High |
| UniST | Grid/Graph | **âœ“**  | **âœ“** | **âœ“** | Low | Low |

<sub>**(a). Still restricted in the same city.**</sub><br>

[1] [PromptST: Prompt-Enhanced Spatio-Temporal Multi-Attribute Prediction](https://arxiv.org/abs/2309.09500), CIKM 2023

[2] [GPT-ST: Generative Pre-Training of Spatio-Temporal Graph Neural Networks](https://proceedings.neurips.cc/paper_files/paper/2023/file/de7858e3e7f9f0f7b2c7bfdc86f6d928-Paper-Conference.pdf), NIPS 2023

[3] [Pre-training enhanced spatial-temporal graph neural network for multivariate time series forecasting](https://dl.acm.org/doi/10.1145/3534678.3539396), KDD 2022

[4] [Spatio-Temporal Self-Supervised Learning for Traffic Flow Prediction](https://dl.acm.org/doi/10.1609/aaai.v37i4.25555), AAAI 2023

[5] [TrafficBERT: Pre-trained model with large-scale data for long-range traffic flow forecasting](), Expert Systems with Applications

[6] [Building transportation foundation model via generative graph transformer](https://www.sciencedirect.com/science/article/pii/S0957417421011179), ITSC 2023

[7] [UrbanGPT: Spatio-Temporal Large Language Models](https://arxiv.org/abs/2403.00813), KDD 2024

[8] [How can large language models understand spatial-temporal data?](https://arxiv.org/abs/2401.14192), arXiv 2024

## Data
We use multiple datasets to demonstrate the UniST, which span various cities and domains. To access the datasets, please refer to [data readme](https://github.com/tsinghua-fib-lab/UniST/blob/main/dataset/README.md).


## âš™ï¸ Installation
### Environment
- Tested OS: Linux
- Python >= 3.9
- torch == 2.0.0
- Tensorboard

### Dependencies:
1. Install Pytorch with the correct CUDA version.
2. Use the `pip install -r requirements.txt` command to install all of the Python modules and packages used in this project.

## ğŸƒ Model Training

Please first navigate to the `src` directory by using the cd command: `cd src`

Then please create a folder named `experiments` to record the training process: `mkdir experiments`

### Stage-1: Pre-training
We provide the scripts under the folder `./scripts/pretrain.sh`. You can train UniST with the Cellular dataset as the following examples:

```python
python main.py --device_id 3 --machine machine  --dataset Crowd --task short --size middle  --mask_strategy_random 'batch' --lr 3e-4 --used_data 'single'  --prompt_ST 0
```

Once your model is trained, you will find the logs recording the training process in the  `./logs/` directory. The folder will be named as the `Pretrain_Dataset_<dataset>_task_<task>`. In the `./experiments/Pretrain_Dataset_<dataset>_task_<task>/model_save/`, you will find the trained model named `model_best.pkl`.

In our experiments, we leverage multiple datasets to enhance UniST. 
If you need to use multiple datasets, please use an asterisk (*) to separate the datasets, *e.g.*, `--dataset Crowd*Cellular*TaxiNYC*TaxiBike*TrafficSH`.

### Stage-2: Prompt-tuning
We provide the scripts under the folder `./scripts/prompt_tuning.sh`. You can fine-tune UniST with the Cellular dataset as the following examples:

```python
python main.py --device_id 2 --machine machine --task short --size middle   --prompt_ST 1  --pred_len 6 --his_len 6  --num_memory_spatial 512 --num_memory_temporal 512  --prompt_content 's_p_c'  --dataset Crowd    --lr 3e-4 --used_data 'single' --file_load_path  pretrained_model_path
```

There are some new parameters to specify:

- `his_len` specifies the input sequence length.
- `pred_len` specifies the prediction horizon.
- `file_load_path` specifies the save path of the pre-trained model, the default is `./experiments/Dataset_<dataset>_task_<task>/model_save/model_best.pkl`
- `num_memory_spatial` and `num_memory_temporal` specify the number of embeddings in the memory pools.
- `prompt_ST` specifies whether perform prompt-tuning: 0 for no prompt and 1 for prompt-tuning.
- `prompt_content` specifies the type of prompt, which can be selected from ['s_p_c','s','c','p','s_c','s_p','p_c'].

Once your model is trained, you will find the logs recording the training process in the  `./logs/` directory. The folder will be named as the `Prompt_Dataset_<dataset>_His_<his_len>_Pred_<pred_len>`. In the `./experiments/Prompt_Dataset_<dataset>_His_<his_len>_Pred_<pred_len>/model_save/`, you will find the fine-tuned model named `model_best.pkl`.

The evaluation results of the testing set can be obtained from `./experiments/Prompt_Mode_finetuning_Dataset_<dataset>_His_<his_len>_Pred_<pred_len>/result.txt`.

## Model Weights
We provide downloads of model weights on xxx. Coming soon.

## ğŸ‘€ Citation

If you find this repo helpful, please cite our paper. 

```latex
@article{yuan2024unist,
  title={UniST: A Prompt-Empowered Universal Model for Urban Spatio-Temporal Prediction},
  author={Yuan, Yuan and Ding, Jingtao and Feng, Jie and Jin, Depeng and Li, Yong},
  journal={arXiv preprint arXiv:2402.11838},
  year={2024}
}
```

## ğŸ™‡â€ Acknowledgement
We appreciate the following GitHub repos a lot for their valuable code and efforts.
- Spatio-temporal prediction benchmark: [https://github.com/chengtan9907/OpenSTL](https://github.com/chengtan9907/OpenSTL)
- Spatio-temporal data: [https://github.com/aptx1231/NYC-Dataset](https://github.com/aptx1231/NYC-Dataset)
- MAE: [https://github.com/facebookresearch/mae](https://github.com/facebookresearch/mae)
- PatchTST: [https://github.com/PatchTST/PatchTST](https://github.com/PatchTST/PatchTST)
- iTransformer: [https://github.com/thuml/iTransformer](https://github.com/thuml/iTransformer)

## ğŸ“§ Contact

If you have any questions or want to use the code, feel free to contact:
* Yuan Yuan (y-yuan20@mails.tsinghua.edu.cn)
ä»€ä¹ˆæ˜¯å¼ é‡ï¼ˆTensorï¼‰-CSDNåšå®¢
å¤šå…ƒæ—¶åºé¢„æµ‹ï¼šç‹¬ç«‹é¢„æµ‹ or è”åˆé¢„æµ‹ï¼Ÿ-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘
ML-NLP/NLP/16.4 textRNN & textCNN at master Â· NLP-LOVE/ML-NLP
ã€è®ºæ–‡ä¸‹é¥­ã€‘PatchTSTä¸­çš„channel-independence-CSDNåšå®¢
3då·ç§¯çš„cnnç½‘ç»œ cnnå·ç§¯è¿ç®—_mob64ca13fb1f2eçš„æŠ€æœ¯åšå®¢_51CTOåšå®¢
3Då·ç§¯ï¼Œä»£ç å®ç° - å´å»ºæ˜wujianming - åšå®¢å›­
Transformerè§£æä¸tensorflowä»£ç è§£è¯» - ä¸è‘—äººé—´é£é›¨é—¨ - åšå®¢å›­
Transformerâ€”â€”patch embeddingä»£ç -CSDNåšå®¢
è®ºæ–‡
æ·±åº¦å­¦ä¹ çš„ä¼˜åŒ–å™¨ï¼ˆå„ç±» optimizer çš„åŸç†ã€ä¼˜ç¼ºç‚¹åŠæ•°å­¦æ¨å¯¼ï¼‰ - FromL77 - åšå®¢å›­
CNNä¸­çš„å‚æ•°è§£é‡ŠåŠè®¡ç®—
nn.LayerNormçš„å®ç°åŠåŸç†-CSDNåšå®¢
è‡ªç›‘ç£å­¦ä¹ ä¹‹æ©ç è‡ªåŠ¨ç¼–ç å™¨(Masked Autoencoders, MAE)â€”â€”éŸ³é¢‘è¯†åˆ«æ–¹é¢_æ©ç è‡ªç¼–ç å™¨-CSDNåšå®¢
Pytorchä¹‹Embeddingä¸Linearçš„çˆ±æ¨çº è‘› - å¥¥è¾° - åšå®¢å›­
ã€Pytorchã€‘nn.Dropoutçš„ç”¨æ³•-CSDNåšå®¢
torch.sort()å’Œtorch.argsort()ç®€è¦ä»‹ç»-CSDNåšå®¢
è¯¦è§£ Pytorch.random-CSDNåšå®¢
å›¾è§£torch.gather()çš„ç”¨æ³•_torch.gather ä¸‰ç»´ä½¿ç”¨æ–¹æ³•-CSDNåšå®¢
å¤§è¯­è¨€æ¨¡å‹çš„é¢„è®­ç»ƒ[3]ä¹‹Prompt Learningï¼šPrompt Engineeringã€Answer engineeringè¯¦è§£-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘
äº”ä¸‡å­—ç»¼è¿°ï¼Prompt-Tuningï¼šæ·±åº¦è§£è¯»ä¸€ç§æ–°çš„å¾®è°ƒèŒƒå¼ - çŸ¥ä¹
